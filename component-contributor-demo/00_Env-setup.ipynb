{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeCon NA 2025 Demo - Environment Setup\n",
    "\n",
    "This notebook sets up a complete Kubernetes environment with Crossplane and KubeVela for the demo.\n",
    "\n",
    "## Prerequisites\n",
    "- k3d installed\n",
    "- kubectl installed\n",
    "- helm installed\n",
    "- Python 3.x with pip\n",
    "- AWS credentials (optional, for AWS provider)\n",
    "\n",
    "## Setup Steps\n",
    "0. Check prerequisites and install Python packages (automated)\n",
    "1. Load configuration\n",
    "2. Create k3d cluster\n",
    "3. Install Crossplane\n",
    "4. Wait for Crossplane CRDs\n",
    "5. Configure AWS Provider\n",
    "6. Apply setup manifests\n",
    "7. Install KubeVela\n",
    "\n",
    "**Important:** Run the cells in order. The first cell will automatically install required Python packages from requirements.txt if they're not already installed.\n",
    "\n",
    "**AWS Setup:** To use AWS resources, create a `.env.aws` file with your credentials before running Step 3.5.\n",
    "\n",
    "**Note:** If you encounter errors, check that all prerequisites are installed and try re-running the failed cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking Prerequisites ===\n",
      "\n",
      "1. Checking Python packages...\n",
      "   ✓ PyYAML is installed\n",
      "\n",
      "2. Checking configuration file...\n",
      "   ✓ config.yaml found\n",
      "\n",
      "3. Checking required tools...\n",
      "   ✓ k3d is installed\n",
      "   ✗ kubectl is NOT working properly\n",
      "   ✓ helm is installed\n",
      "   ✓ vela is installed\n",
      "\n",
      "⚠️  WARNING: Some tools are missing. Please install them before proceeding.\n",
      "   - k3d: https://k3d.io/\n",
      "   - kubectl: https://kubernetes.io/docs/tasks/tools/\n",
      "   - helm: https://helm.sh/docs/intro/install/\n",
      "   - vela: https://kubevela.io/docs/installation/kubernetes/#install-vela-cli\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites Check and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"=== Checking Prerequisites ===\\n\")\n",
    "\n",
    "# Check Python packages\n",
    "print(\"1. Checking Python packages...\")\n",
    "try:\n",
    "    import yaml\n",
    "    print(\"   ✓ PyYAML is installed\")\n",
    "except ImportError:\n",
    "    print(\"   ✗ PyYAML is NOT installed\")\n",
    "    print(\"   Installing required packages from requirements.txt...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"])\n",
    "    print(\"   ✓ Packages installed successfully\")\n",
    "    import yaml\n",
    "\n",
    "# Check if config.yaml exists\n",
    "print(\"\\n2. Checking configuration file...\")\n",
    "if os.path.exists('config.yaml'):\n",
    "    print(\"   ✓ config.yaml found\")\n",
    "else:\n",
    "    print(\"   ✗ config.yaml NOT found\")\n",
    "    raise FileNotFoundError(\"config.yaml is missing. Please ensure it exists in the current directory.\")\n",
    "\n",
    "# Check command-line tools\n",
    "print(\"\\n3. Checking required tools...\")\n",
    "tools = {\n",
    "    'k3d': 'k3d version',\n",
    "    'kubectl': 'kubectl version --client --short',\n",
    "    'helm': 'helm version --short',\n",
    "    'vela': 'vela version'\n",
    "}\n",
    "\n",
    "all_tools_ok = True\n",
    "for tool, cmd in tools.items():\n",
    "    try:\n",
    "        result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   ✓ {tool} is installed\")\n",
    "        else:\n",
    "            print(f\"   ✗ {tool} is NOT working properly\")\n",
    "            all_tools_ok = False\n",
    "    except (subprocess.TimeoutExpired, FileNotFoundError):\n",
    "        print(f\"   ✗ {tool} is NOT installed\")\n",
    "        all_tools_ok = False\n",
    "\n",
    "if not all_tools_ok:\n",
    "    print(\"\\n⚠️  WARNING: Some tools are missing. Please install them before proceeding.\")\n",
    "    print(\"   - k3d: https://k3d.io/\")\n",
    "    print(\"   - kubectl: https://kubernetes.io/docs/tasks/tools/\")\n",
    "    print(\"   - helm: https://helm.sh/docs/intro/install/\")\n",
    "    print(\"   - vela: https://kubevela.io/docs/installation/kubernetes/#install-vela-cli\")\n",
    "else:\n",
    "    print(\"\\n✓ All prerequisites are satisfied!\")\n",
    "    print(\"Ready to proceed with the setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully:\n",
      "  Cluster name: kubecon-NA25\n",
      "  API port: 6443\n",
      "  HTTP port: 8090\n",
      "  Crossplane namespace: crossplane-system\n",
      "  Minimum CRDs: 15\n",
      "  Setup directory: setup\n",
      "\n",
      "Environment variables set and saved to .env.sh\n",
      "Ready to proceed with setup!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Load configuration from config.yaml\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract values for use in notebook\n",
    "cluster_name = config['cluster']['name']\n",
    "api_port = config['cluster']['api_port']\n",
    "http_port = config['cluster']['http_port']\n",
    "crossplane_namespace = config['crossplane']['namespace']\n",
    "min_crds = config['crossplane']['min_crds']\n",
    "setup_dir = config['setup']['manifests_dir']\n",
    "\n",
    "# Store in environment for bash cells\n",
    "os.environ['CLUSTER_NAME'] = cluster_name\n",
    "os.environ['API_PORT'] = str(api_port)\n",
    "os.environ['HTTP_PORT'] = str(http_port)\n",
    "os.environ['CROSSPLANE_NAMESPACE'] = crossplane_namespace\n",
    "os.environ['MIN_CRDS'] = str(min_crds)\n",
    "os.environ['SETUP_DIR'] = setup_dir\n",
    "\n",
    "# Also write to a shell file that can be sourced\n",
    "with open('.env.sh', 'w') as f:\n",
    "    f.write(f'export CLUSTER_NAME=\"{cluster_name}\"\\n')\n",
    "    f.write(f'export API_PORT=\"{api_port}\"\\n')\n",
    "    f.write(f'export HTTP_PORT=\"{http_port}\"\\n')\n",
    "    f.write(f'export CROSSPLANE_NAMESPACE=\"{crossplane_namespace}\"\\n')\n",
    "    f.write(f'export MIN_CRDS=\"{min_crds}\"\\n')\n",
    "    f.write(f'export SETUP_DIR=\"{setup_dir}\"\\n')\n",
    "\n",
    "print(\"Configuration loaded successfully:\")\n",
    "print(f\"  Cluster name: {cluster_name}\")\n",
    "print(f\"  API port: {api_port}\")\n",
    "print(f\"  HTTP port: {http_port}\")\n",
    "print(f\"  Crossplane namespace: {crossplane_namespace}\")\n",
    "print(f\"  Minimum CRDs: {min_crds}\")\n",
    "print(f\"  Setup directory: {setup_dir}\")\n",
    "print(\"\\nEnvironment variables set and saved to .env.sh\")\n",
    "print(\"Ready to proceed with setup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create k3d Cluster\n",
    "\n",
    "Creating a lightweight Kubernetes cluster using k3d with custom port mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Creating k3d cluster with local registry ===\n",
      "Cleaning up any existing cluster...\n",
      "\u001b[36mINFO\u001b[0m[0000] No nodes found for cluster 'kubecon-NA25', nothing to delete. \n",
      "\u001b[36mINFO\u001b[0m[0000] No clusters found                            \n",
      "Cleaning up any existing registry...\n",
      "\n",
      "Creating local Docker registry...\n",
      "\u001b[36mINFO\u001b[0m[0000] Creating node 'k3d-registry.localhost'       \n",
      "\u001b[36mINFO\u001b[0m[0000] Successfully created registry 'k3d-registry.localhost' \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting node 'k3d-registry.localhost'       \n",
      "\u001b[36mINFO\u001b[0m[0000] Successfully created registry 'k3d-registry.localhost' \n",
      "# You can now use the registry like this (example):\n",
      "# 1. create a new cluster that uses this registry\n",
      "k3d cluster create --registry-use k3d-registry.localhost:5000\n",
      "\n",
      "# 2. tag an existing local image to be pushed to the registry\n",
      "docker tag nginx:latest k3d-registry.localhost:5000/mynginx:v0.1\n",
      "\n",
      "# 3. push that image to the registry\n",
      "docker push k3d-registry.localhost:5000/mynginx:v0.1\n",
      "\n",
      "# 4. run a pod that uses this image\n",
      "kubectl run mynginx --image k3d-registry.localhost:5000/mynginx:v0.1\n",
      "\n",
      "✓ Registry created successfully at localhost:5000\n",
      "\n",
      "Creating k3d cluster: kubecon-NA25\n",
      "\u001b[36mINFO\u001b[0m[0000] portmapping '8090:80' targets the loadbalancer: defaulting to [servers:*:proxy agents:*:proxy] \n",
      "\u001b[36mINFO\u001b[0m[0000] Prep: Network                                \n",
      "\u001b[36mINFO\u001b[0m[0000] Created network 'k3d-kubecon-NA25'           \n",
      "\u001b[36mINFO\u001b[0m[0000] Created image volume k3d-kubecon-NA25-images \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting new tools node...                   \n",
      "\u001b[36mINFO\u001b[0m[0000] Starting node 'k3d-kubecon-NA25-tools'       \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating node 'k3d-kubecon-NA25-server-0'    \n",
      "\u001b[36mINFO\u001b[0m[0001] Creating LoadBalancer 'k3d-kubecon-NA25-serverlb' \n",
      "\u001b[36mINFO\u001b[0m[0001] Using the k3d-tools node to gather environment information \n",
      "\u001b[36mINFO\u001b[0m[0001] HostIP: using network gateway 172.21.0.1 address \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting cluster 'kubecon-NA25'              \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting servers...                          \n",
      "\u001b[36mINFO\u001b[0m[0001] Starting node 'k3d-kubecon-NA25-server-0'    \n",
      "\u001b[36mINFO\u001b[0m[0004] All agents already running.                  \n",
      "\u001b[36mINFO\u001b[0m[0004] Starting helpers...                          \n",
      "\u001b[36mINFO\u001b[0m[0004] Starting node 'k3d-kubecon-NA25-serverlb'    \n",
      "\u001b[36mINFO\u001b[0m[0010] Injecting records for hostAliases (incl. host.k3d.internal) and for 3 network members into CoreDNS configmap... \n",
      "\u001b[36mINFO\u001b[0m[0014] Cluster 'kubecon-NA25' created successfully! \n",
      "\u001b[36mINFO\u001b[0m[0014] You can now use it like this:                \n",
      "kubectl cluster-info\n",
      "✓ Cluster created successfully\n",
      "\n",
      "Setting kubectl context to k3d-kubecon-NA25...\n",
      "Switched to context \"k3d-kubecon-NA25\".\n",
      "Verifying cluster access...\n",
      "✓ Cluster is accessible\n",
      "Current context: k3d-kubecon-NA25\n",
      "NAME                        STATUS   ROLES                  AGE   VERSION\n",
      "k3d-kubecon-na25-server-0   Ready    control-plane,master   12s   v1.31.5+k3s1\n",
      "\n",
      "=== Registry Setup Complete ===\n",
      "Registry URL: localhost:5000\n",
      "Registry status:\n",
      "NAME                     ROLE       CLUSTER   STATUS\n",
      "k3d-registry.localhost   registry             running\n",
      "\n",
      "5aaaac782015   registry:2                                                                                \"/entrypoint.sh /etc…\"   18 seconds ago   Up 17 seconds   0.0.0.0:5000->5000/tcp                                            k3d-registry.localhost\n",
      "\n",
      "To push images: docker tag <image> localhost:5000/<image>:<tag>\n",
      "                docker push localhost:5000/<image>:<tag>\n",
      "\n",
      "In k3d cluster, use: k3d-registry.localhost:5000/<image>:<tag>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e  # Exit on error\n",
    "source .env.sh  # Load configuration\n",
    "\n",
    "echo \"=== Step 1: Creating k3d cluster with local registry ===\"\n",
    "\n",
    "# Delete existing cluster if it exists\n",
    "echo \"Cleaning up any existing cluster...\"\n",
    "k3d cluster delete $CLUSTER_NAME 2>/dev/null || echo \"No existing cluster to delete\"\n",
    "\n",
    "# Delete existing registry if it exists\n",
    "echo \"Cleaning up any existing registry...\"\n",
    "k3d registry delete registry.localhost 2>/dev/null || echo \"No existing registry to delete\"\n",
    "\n",
    "# Create registry first\n",
    "echo \"\"\n",
    "echo \"Creating local Docker registry...\"\n",
    "if k3d registry create registry.localhost --port 0.0.0.0:5000; then\n",
    "    echo \"✓ Registry created successfully at localhost:5000\"\n",
    "else\n",
    "    echo \"✗ Failed to create registry\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Create cluster and connect it to the registry\n",
    "echo \"\"\n",
    "echo \"Creating k3d cluster: $CLUSTER_NAME\"\n",
    "if k3d cluster create $CLUSTER_NAME \\\n",
    "    --api-port $API_PORT \\\n",
    "    -p \"${HTTP_PORT}:80@loadbalancer\" \\\n",
    "    --k3s-arg=\"--kubelet-arg=max-open-files=1000000@server:*\" \\\n",
    "    --registry-use k3d-registry.localhost:5000 \\\n",
    "    --wait; then\n",
    "    echo \"✓ Cluster created successfully\"\n",
    "else\n",
    "    echo \"✗ Failed to create cluster\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# IMPORTANT: Set kubectl context to the new cluster\n",
    "echo \"\"\n",
    "echo \"Setting kubectl context to k3d-$CLUSTER_NAME...\"\n",
    "kubectl config use-context \"k3d-$CLUSTER_NAME\"\n",
    "\n",
    "# Verify cluster is accessible\n",
    "echo \"Verifying cluster access...\"\n",
    "if kubectl cluster-info &>/dev/null; then\n",
    "    echo \"✓ Cluster is accessible\"\n",
    "    echo \"Current context: $(kubectl config current-context)\"\n",
    "    kubectl get nodes\n",
    "else\n",
    "    echo \"✗ Cannot access cluster\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Verify registry\n",
    "echo \"\"\n",
    "echo \"=== Registry Setup Complete ===\"\n",
    "echo \"Registry URL: localhost:5000\"\n",
    "echo \"Registry status:\"\n",
    "k3d registry list\n",
    "echo \"\"\n",
    "docker ps | grep registry || echo \"Warning: Registry container not visible\"\n",
    "echo \"\"\n",
    "echo \"To push images: docker tag <image> localhost:5000/<image>:<tag>\"\n",
    "echo \"                docker push localhost:5000/<image>:<tag>\"\n",
    "echo \"\"\n",
    "echo \"In k3d cluster, use: k3d-registry.localhost:5000/<image>:<tag>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Crossplane\n",
    "\n",
    "Installing Crossplane for infrastructure orchestration and composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 2: Installing Crossplane ===\n",
      "Adding Crossplane helm repository...\n",
      "\"crossplane-stable\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"k8sgpt\" chart repository\n",
      "...Successfully got an update from the \"kubevela\" chart repository\n",
      "...Successfully got an update from the \"crossplane-stable\" chart repository\n",
      "...Successfully got an update from the \"localstack-repo\" chart repository\n",
      "...Successfully got an update from the \"datadog\" chart repository\n",
      "...Successfully got an update from the \"dapr\" chart repository\n",
      "...Successfully got an update from the \"cnpg\" chart repository\n",
      "...Successfully got an update from the \"robusta\" chart repository\n",
      "...Successfully got an update from the \"atmos-helm-release\" chart repository\n",
      "...Successfully got an update from the \"loft\" chart repository\n",
      "...Successfully got an update from the \"loft-platform\" chart repository\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "Installing Crossplane...\n",
      "NAME: crossplane\n",
      "LAST DEPLOYED: Fri Nov  7 15:43:49 2025\n",
      "NAMESPACE: crossplane-system\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "Release: crossplane\n",
      "\n",
      "Chart Name: crossplane\n",
      "Chart Description: Crossplane is an open source Kubernetes add-on that enables platform teams to assemble infrastructure from multiple vendors, and expose higher level self-service APIs for application teams to consume.\n",
      "Chart Version: 2.1.0\n",
      "Chart Application Version: 2.1.0\n",
      "\n",
      "Kube Version: v1.31.5+k3s1\n",
      "✓ Crossplane helm chart install completed\n",
      "Waiting for Crossplane pods to be ready...\n",
      "pod/crossplane-77fdff5bbd-4gc2z condition met\n",
      "pod/crossplane-rbac-manager-6bddf6988d-9fkd6 condition met\n",
      "✓ Crossplane controller is ready\n",
      "Crossplane installation complete!\n",
      "NAME                                       READY   STATUS    RESTARTS   AGE\n",
      "crossplane-77fdff5bbd-4gc2z                1/1     Running   0          13s\n",
      "crossplane-rbac-manager-6bddf6988d-9fkd6   1/1     Running   0          13s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e  # Exit on error\n",
    "source .env.sh  # Load configuration\n",
    "\n",
    "echo \"=== Step 2: Installing Crossplane ===\"\n",
    "\n",
    "# Add and update helm repo\n",
    "echo \"Adding Crossplane helm repository...\"\n",
    "helm repo add crossplane-stable https://charts.crossplane.io/stable 2>/dev/null || echo \"Repository already exists\"\n",
    "helm repo update\n",
    "\n",
    "# Check if Crossplane is already installed\n",
    "if helm list -n $CROSSPLANE_NAMESPACE | grep -q crossplane; then\n",
    "    echo \"⚠ Crossplane is already installed. Upgrading...\"\n",
    "    HELM_CMD=\"upgrade\"\n",
    "else\n",
    "    echo \"Installing Crossplane...\"\n",
    "    HELM_CMD=\"install\"\n",
    "fi\n",
    "\n",
    "# Install or upgrade Crossplane\n",
    "if helm $HELM_CMD crossplane crossplane-stable/crossplane \\\n",
    "    --namespace $CROSSPLANE_NAMESPACE \\\n",
    "    --create-namespace \\\n",
    "    --wait \\\n",
    "    --timeout 10m; then\n",
    "    echo \"✓ Crossplane helm chart $HELM_CMD completed\"\n",
    "else\n",
    "    echo \"✗ Failed to $HELM_CMD Crossplane\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Wait for pods to be ready\n",
    "echo \"Waiting for Crossplane pods to be ready...\"\n",
    "if kubectl wait --namespace $CROSSPLANE_NAMESPACE \\\n",
    "    --for=condition=ready pod \\\n",
    "    --selector=app.kubernetes.io/component=cloud-infrastructure-controller \\\n",
    "    --timeout=1200s; then\n",
    "    echo \"✓ Crossplane controller is ready\"\n",
    "else\n",
    "    echo \"✗ Crossplane controller failed to become ready\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"Crossplane installation complete!\"\n",
    "kubectl get pods -n $CROSSPLANE_NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wait for Crossplane CRDs\n",
    "\n",
    "Crossplane installs various Custom Resource Definitions (CRDs) that are needed for the next steps. This cell waits until the minimum number of CRDs are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 3: Waiting for Crossplane CRDs ===\n",
      "Waiting for at least 15 Crossplane CRDs to be installed...\n",
      "Attempt 1/60: Found       21 Crossplane CRDs\n",
      "✓ Sufficient CRDs are available (      21 >= 15)\n",
      "\n",
      "Current Crossplane pods:\n",
      "NAME                                       READY   STATUS    RESTARTS   AGE\n",
      "crossplane-77fdff5bbd-4gc2z                1/1     Running   0          14s\n",
      "crossplane-rbac-manager-6bddf6988d-9fkd6   1/1     Running   0          14s\n",
      "\n",
      "Sample Crossplane CRDs:\n",
      "compositeresourcedefinitions        xrd,xrds     apiextensions.crossplane.io/v2         false        CompositeResourceDefinition\n",
      "compositionrevisions                comprev      apiextensions.crossplane.io/v1         false        CompositionRevision\n",
      "compositions                        comp         apiextensions.crossplane.io/v1         false        Composition\n",
      "environmentconfigs                  envcfg       apiextensions.crossplane.io/v1beta1    false        EnvironmentConfig\n",
      "managedresourceactivationpolicies   mrap         apiextensions.crossplane.io/v1alpha1   false        ManagedResourceActivationPolicy\n",
      "managedresourcedefinitions          mrd,mrds     apiextensions.crossplane.io/v1alpha1   false        ManagedResourceDefinition\n",
      "usages                                           apiextensions.crossplane.io/v1beta1    false        Usage\n",
      "cronoperations                      cronops      ops.crossplane.io/v1alpha1             false        CronOperation\n",
      "operations                          ops          ops.crossplane.io/v1alpha1             false        Operation\n",
      "watchoperations                     watchops     ops.crossplane.io/v1alpha1             false        WatchOperation\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e  # Exit on error\n",
    "source .env.sh  # Load configuration\n",
    "\n",
    "echo \"=== Step 3: Waiting for Crossplane CRDs ===\"\n",
    "\n",
    "MAX_RETRIES=60\n",
    "RETRY_DELAY=5\n",
    "\n",
    "echo \"Waiting for at least $MIN_CRDS Crossplane CRDs to be installed...\"\n",
    "\n",
    "for i in $(seq 1 $MAX_RETRIES); do\n",
    "    CRD_COUNT=$(kubectl api-resources | grep crossplane | wc -l)\n",
    "    echo \"Attempt $i/$MAX_RETRIES: Found $CRD_COUNT Crossplane CRDs\"\n",
    "    \n",
    "    if [ $CRD_COUNT -ge $MIN_CRDS ]; then\n",
    "        echo \"✓ Sufficient CRDs are available ($CRD_COUNT >= $MIN_CRDS)\"\n",
    "        break\n",
    "    fi\n",
    "    \n",
    "    if [ $i -eq $MAX_RETRIES ]; then\n",
    "        echo \"✗ Timeout: Only $CRD_COUNT CRDs found after ${MAX_RETRIES} attempts\"\n",
    "        exit 1\n",
    "    fi\n",
    "    \n",
    "    sleep $RETRY_DELAY\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"Current Crossplane pods:\"\n",
    "kubectl get pods -n $CROSSPLANE_NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"Sample Crossplane CRDs:\"\n",
    "kubectl api-resources | grep crossplane | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 3.5: Configuring AWS Provider ===\n",
      "AWS credentials found, configuring Crossplane...\n",
      "1. Installing Crossplane AWS Provider...\n",
      "provider.pkg.crossplane.io/upbound-provider-aws-dynamodb created\n",
      "provider.pkg.crossplane.io/upbound-provider-aws-s3 created\n",
      "   Waiting for provider to be installed...\n",
      "provider.pkg.crossplane.io/upbound-provider-aws-dynamodb condition met\n",
      "provider.pkg.crossplane.io/upbound-provider-aws-s3 condition met\n",
      "   Waiting for provider to be healthy...\n",
      "provider.pkg.crossplane.io/upbound-provider-aws-dynamodb condition met\n",
      "provider.pkg.crossplane.io/upbound-provider-aws-s3 condition met\n",
      "✓ AWS Provider installed\n",
      "\n",
      "2. Creating Kubernetes secret with AWS credentials...\n",
      "   Including session token for temporary credentials\n",
      "secret/aws-credentials created\n",
      "✓ AWS credentials secret created\n",
      "\n",
      "3. Creating ProviderConfig for AWS...\n",
      "providerconfig.aws.upbound.io/default created\n",
      "✓ ProviderConfig created\n",
      "\n",
      "=== AWS Provider Configuration Complete ===\n",
      "✓ Provider: provider-aws-dynamodb\n",
      "✓ Credentials: Configured from .env.aws\n",
      "✓ Region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e  # Exit on error\n",
    "source .env.sh  # Load configuration\n",
    "\n",
    "echo \"=== Step 3.5: Configuring AWS Provider ===\"\n",
    "\n",
    "# Check if .env.aws file exists\n",
    "if [ ! -f \"../.env.aws\" ]; then\n",
    "    echo \"⚠ Warning: .env.aws file not found\"\n",
    "    echo \"Creating template .env.aws file...\"\n",
    "    cat > ../.env.aws << 'EOF'\n",
    "# AWS Credentials for Crossplane\n",
    "AWS_ACCESS_KEY_ID=your-access-key-id\n",
    "AWS_SECRET_ACCESS_KEY=your-secret-access-key\n",
    "AWS_DEFAULT_REGION=us-west-2\n",
    "EOF\n",
    "    echo \"✓ Template created. Please edit .env.aws with your credentials and re-run this cell.\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "# Source AWS credentials\n",
    "source ../.env.aws\n",
    "\n",
    "# Check if credentials are set\n",
    "if [ \"$AWS_ACCESS_KEY_ID\" == \"your-access-key-id\" ] || [ -z \"$AWS_ACCESS_KEY_ID\" ]; then\n",
    "    echo \"⚠ Warning: AWS credentials not configured in .env.aws\"\n",
    "    echo \"Please edit .env.aws with your actual AWS credentials and re-run this cell.\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "echo \"AWS credentials found, configuring Crossplane...\"\n",
    "\n",
    "# Install AWS Provider\n",
    "echo \"1. Installing Crossplane AWS Provider...\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: pkg.crossplane.io/v1\n",
    "kind: Provider\n",
    "metadata:\n",
    "  name: upbound-provider-aws-dynamodb\n",
    "spec:\n",
    "  package: xpkg.upbound.io/upbound/provider-aws-dynamodb:v1.23.2\n",
    "---\n",
    "apiVersion: pkg.crossplane.io/v1\n",
    "kind: Provider\n",
    "metadata:\n",
    "  name: upbound-provider-aws-s3\n",
    "spec:\n",
    "  package: xpkg.upbound.io/upbound/provider-aws-s3:v1.23.2\n",
    "EOF\n",
    "\n",
    "echo \"   Waiting for provider to be installed...\"\n",
    "kubectl wait --for=condition=installed --timeout=300s provider.pkg.crossplane.io/upbound-provider-aws-dynamodb\n",
    "kubectl wait --for=condition=installed --timeout=300s provider.pkg.crossplane.io/upbound-provider-aws-s3\n",
    "\n",
    "echo \"   Waiting for provider to be healthy...\"\n",
    "kubectl wait --for=condition=healthy --timeout=300s provider.pkg.crossplane.io/upbound-provider-aws-dynamodb\n",
    "kubectl wait --for=condition=healthy --timeout=300s provider.pkg.crossplane.io/upbound-provider-aws-s3\n",
    "\n",
    "echo \"✓ AWS Provider installed\"\n",
    "\n",
    "# Create Kubernetes secret with AWS credentials\n",
    "echo \"\"\n",
    "echo \"2. Creating Kubernetes secret with AWS credentials...\"\n",
    "# Create credentials string with session token if available\n",
    "if [ -n \"$AWS_SESSION_TOKEN\" ]; then\n",
    "    CREDENTIALS_STRING=\"[default]\n",
    "aws_access_key_id = ${AWS_ACCESS_KEY_ID}\n",
    "aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}\n",
    "aws_session_token = ${AWS_SESSION_TOKEN}\"\n",
    "    echo \"   Including session token for temporary credentials\"\n",
    "else\n",
    "    CREDENTIALS_STRING=\"[default]\n",
    "aws_access_key_id = ${AWS_ACCESS_KEY_ID}\n",
    "aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}\"\n",
    "    echo \"   Using long-term credentials (no session token)\"\n",
    "fi\n",
    "\n",
    "kubectl create secret generic aws-credentials \\\n",
    "    -n $CROSSPLANE_NAMESPACE \\\n",
    "    --from-literal=credentials=\"$CREDENTIALS_STRING\" \\\n",
    "    --dry-run=client -o yaml | kubectl apply -f -\n",
    "\n",
    "echo \"✓ AWS credentials secret created\"\n",
    "\n",
    "# Create ProviderConfig\n",
    "echo \"\"\n",
    "echo \"3. Creating ProviderConfig for AWS...\"\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: aws.upbound.io/v1beta1\n",
    "kind: ProviderConfig\n",
    "metadata:\n",
    "  name: default\n",
    "spec:\n",
    "  credentials:\n",
    "    source: Secret\n",
    "    secretRef:\n",
    "      namespace: $CROSSPLANE_NAMESPACE\n",
    "      name: aws-credentials\n",
    "      key: credentials\n",
    "EOF\n",
    "\n",
    "echo \"✓ ProviderConfig created\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== AWS Provider Configuration Complete ===\"\n",
    "echo \"✓ Provider: provider-aws-dynamodb\"\n",
    "echo \"✓ Credentials: Configured from .env.aws\"\n",
    "echo \"✓ Region: ${AWS_DEFAULT_REGION}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: Configure AWS Provider for Crossplane\n",
    "\n",
    "Configure Crossplane to use AWS credentials from `.env.aws` file.\n",
    "\n",
    "**Important:** Make sure you have filled in your AWS credentials in the `.env.aws` file before running this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply Setup Manifests\n",
    "\n",
    "Applying Crossplane providers, configurations, and compositions from the setup directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 4: Applying Setup Manifests ===\n",
      "Applying manifests from setup...\n",
      "function.pkg.crossplane.io/function-patch-and-transform created\n",
      "provider.pkg.crossplane.io/provider-kubernetes created\n",
      "deploymentruntimeconfig.pkg.crossplane.io/provider-kubernetes created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/provider-kubernetes-cluster-admin created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: resource mapping not found for name: \"default\" namespace: \"\" from \"setup/kubernetes-provider.yaml\": no matches for kind \"ProviderConfig\" in version \"kubernetes.crossplane.io/v1alpha1\"\n",
      "ensure CRDs are installed first\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Some manifests may have failed to apply (CRDs might not be ready yet)\n",
      "\n",
      "Waiting for providerconfigs CRD to be available...\n",
      "✓ ProviderConfigs CRD is available\n",
      "\n",
      "Waiting for Crossplane function pods...\n",
      "pod/function-patch-and-transform-201f894df2f6-67b678d9d6-lg5bz condition met\n",
      "✓ Function pods are ready\n",
      "\n",
      "Waiting for Crossplane provider pods...\n",
      "pod/provider-kubernetes-71953a1e5c15-6bb86d7877-jk2nv condition met\n",
      "✓ Provider pods are ready\n",
      "\n",
      "Re-applying manifests to ensure configuration...\n",
      "function.pkg.crossplane.io/function-patch-and-transform unchanged\n",
      "provider.pkg.crossplane.io/provider-kubernetes unchanged\n",
      "deploymentruntimeconfig.pkg.crossplane.io/provider-kubernetes unchanged\n",
      "clusterrolebinding.rbac.authorization.k8s.io/provider-kubernetes-cluster-admin unchanged\n",
      "providerconfig.kubernetes.crossplane.io/default created\n",
      "\n",
      "✓ Crossplane setup complete!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e  # Exit on error\n",
    "source .env.sh  # Load configuration\n",
    "\n",
    "echo \"=== Step 4: Applying Setup Manifests ===\"\n",
    "\n",
    "# Check if setup directory exists\n",
    "if [ ! -d \"$SETUP_DIR\" ]; then\n",
    "    echo \"⚠ Warning: Setup directory '$SETUP_DIR' not found\"\n",
    "    echo \"Creating placeholder directory...\"\n",
    "    mkdir -p \"$SETUP_DIR\"\n",
    "    echo \"Please add your Crossplane provider and configuration files to the '$SETUP_DIR' directory\"\n",
    "    echo \"Then re-run this cell to apply them\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "# Check if directory has any yaml files\n",
    "if [ -z \"$(find $SETUP_DIR -maxdepth 1 -name \"*.yaml\" -o -name \"*.yml\" 2>/dev/null)\" ]; then\n",
    "    echo \"⚠ Warning: No YAML files found in '$SETUP_DIR' directory\"\n",
    "    echo \"Skipping manifest application\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "# Apply manifests\n",
    "echo \"Applying manifests from $SETUP_DIR...\"\n",
    "if kubectl apply -f $SETUP_DIR/; then\n",
    "    echo \"✓ Initial manifests applied\"\n",
    "else\n",
    "    echo \"⚠ Some manifests may have failed to apply (CRDs might not be ready yet)\"\n",
    "fi\n",
    "\n",
    "# Wait for provider configs CRD to be available\n",
    "echo \"\"\n",
    "echo \"Waiting for providerconfigs CRD to be available...\"\n",
    "MAX_RETRIES=60\n",
    "for i in $(seq 1 $MAX_RETRIES); do\n",
    "    if kubectl api-resources | grep crossplane | grep -q providerconfigs; then\n",
    "        echo \"✓ ProviderConfigs CRD is available\"\n",
    "        break\n",
    "    fi\n",
    "    \n",
    "    if [ $i -eq $MAX_RETRIES ]; then\n",
    "        echo \"⚠ Warning: providerconfigs CRD not found, but continuing...\"\n",
    "        exit 0\n",
    "    fi\n",
    "    \n",
    "    sleep 5\n",
    "done\n",
    "\n",
    "# Wait for function pods\n",
    "echo \"\"\n",
    "echo \"Waiting for Crossplane function pods...\"\n",
    "if kubectl wait --namespace $CROSSPLANE_NAMESPACE \\\n",
    "    --for=condition=ready pod \\\n",
    "    --selector=pkg.crossplane.io/function=function-patch-and-transform \\\n",
    "    --timeout=1200s 2>/dev/null; then\n",
    "    echo \"✓ Function pods are ready\"\n",
    "else\n",
    "    echo \"⚠ Function pods not found or not ready yet (may not be installed)\"\n",
    "fi\n",
    "\n",
    "# Wait for provider pods\n",
    "echo \"\"\n",
    "echo \"Waiting for Crossplane provider pods...\"\n",
    "if kubectl wait --namespace $CROSSPLANE_NAMESPACE \\\n",
    "    --for=condition=ready pod \\\n",
    "    --selector=pkg.crossplane.io/provider=provider-kubernetes \\\n",
    "    --timeout=1200s 2>/dev/null; then\n",
    "    echo \"✓ Provider pods are ready\"\n",
    "else\n",
    "    echo \"⚠ Provider pods not found or not ready yet (may not be installed)\"\n",
    "fi\n",
    "\n",
    "# Re-apply manifests to ensure everything is configured\n",
    "echo \"\"\n",
    "echo \"Re-applying manifests to ensure configuration...\"\n",
    "kubectl apply -f $SETUP_DIR/ 2>/dev/null || echo \"⚠ Some resources may already exist\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Crossplane setup complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Install KubeVela\n",
    "\n",
    "Installing KubeVela for application delivery and management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 5: Installing KubeVela ===\n",
      "Adding KubeVela helm repository...\n",
      "Repository already exists\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"localstack-repo\" chart repository\n",
      "...Successfully got an update from the \"k8sgpt\" chart repository\n",
      "...Successfully got an update from the \"crossplane-stable\" chart repository\n",
      "...Successfully got an update from the \"kubevela\" chart repository\n",
      "...Successfully got an update from the \"datadog\" chart repository\n",
      "...Successfully got an update from the \"dapr\" chart repository\n",
      "...Successfully got an update from the \"cnpg\" chart repository\n",
      "...Successfully got an update from the \"robusta\" chart repository\n",
      "...Successfully got an update from the \"atmos-helm-release\" chart repository\n",
      "...Successfully got an update from the \"loft-platform\" chart repository\n",
      "...Successfully got an update from the \"loft\" chart repository\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "Installing KubeVela...\n",
      "NAME: kubevela\n",
      "LAST DEPLOYED: Fri Nov  7 15:45:00 2025\n",
      "NAMESPACE: vela-system\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "NOTES:\n",
      "Welcome to use the KubeVela! Enjoy your shipping application journey!\n",
      "\n",
      "                                   ,\n",
      "                                   //,\n",
      "                                   ////\n",
      "                               ./  /////*\n",
      "                             ,///  ///////\n",
      "                           ./////  ////////\n",
      "                          ///////  /////////\n",
      "                         ////////  //////////\n",
      "                       ,/////////  ///////////\n",
      "                      ,//////////  ///////////.\n",
      "                     .///////////  ////////////\n",
      "                     ////////////  ////////////.\n",
      "                    *////////////  ////////////*\n",
      "       #@@@@@@@@@@@*     ..,,***/  /////////////\n",
      "        /@@@@@@@@@@@#\n",
      "         *@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@&\n",
      "          .@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@.\n",
      "\n",
      "              @@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "                .&@@@*    *@@@&    ,@@@&.\n",
      "\n",
      "       _  __       _          __     __     _\n",
      "      | |/ /_   _ | |__    ___\\ \\   / /___ | |  __ _\n",
      "      | ' /| | | || '_ \\  / _ \\\\ \\ / // _ \\| | / _` |\n",
      "      | . \\| |_| || |_) ||  __/ \\ V /|  __/| || (_| |\n",
      "      |_|\\_\\\\__,_||_.__/  \\___|  \\_/  \\___||_| \\__,_|\n",
      "\n",
      "\n",
      "You can refer to https://kubevela.io for more details.\n",
      "\n",
      "SECURITY RECOMMENDATION: Both authentication and definition validation are disabled.\n",
      "   If KubeVela is running with cluster-admin or other high-level permissions,\n",
      "   consider enabling one or both security features:\n",
      "\n",
      "   1. Authentication with impersonation (recommended for multi-tenant environments):\n",
      "      --set authentication.enabled=true \n",
      "      --set authentication.withUser=true\n",
      "      This makes KubeVela impersonate the requesting user, applying their RBAC permissions.\n",
      "      Note: Both flags must be enabled for user impersonation to work.\n",
      "\n",
      "   2. Definition permission validation (lightweight RBAC for definitions):\n",
      "      --set authorization.definitionValidationEnabled=true\n",
      "      This ensures users can only reference definitions they have access to.\n",
      "\n",
      "   Using both features together provides defense in depth.\n",
      "   Without these protections, users can leverage KubeVela's permissions to deploy\n",
      "   resources beyond their intended access level.\n",
      "✓ KubeVela helm chart install completed\n",
      "Waiting for KubeVela pods to be ready...\n",
      "pod/kubevela-vela-core-6664f88b6b-xt5qs condition met\n",
      "✓ KubeVela controller is ready\n",
      "\n",
      "KubeVela installation complete!\n",
      "NAME                                        READY   STATUS    RESTARTS   AGE\n",
      "kubevela-cluster-gateway-6454cbb899-97pbn   1/1     Running   0          48s\n",
      "kubevela-vela-core-6664f88b6b-xt5qs         1/1     Running   0          48s\n",
      "\n",
      "Checking KubeVela version...\n",
      "oamdev/vela-core:v1.10.4\n",
      "\n",
      "Installing velaux...\n",
      "Addon velaux enabled successfully.\n",
      "Please access addon-velaux from the following endpoints:\n",
      "+---------+---------------+-----------------------------------+--------------------------------+-------+\n",
      "| CLUSTER |   COMPONENT   |     REF(KIND/NAMESPACE/NAME)      |            ENDPOINT            | INNER |\n",
      "+---------+---------------+-----------------------------------+--------------------------------+-------+\n",
      "| local   | velaux-server | Service/vela-system/velaux-server | velaux-server.vela-system:8000 | true  |\n",
      "+---------+---------------+-----------------------------------+--------------------------------+-------+\n",
      "    To open the dashboard directly by port-forward:\n",
      "\n",
      "    vela port-forward -n vela-system addon-velaux 8000:8000\n",
      "\n",
      "    Please refer to https://kubevela.io/docs/reference/addons/velaux for more VelaUX addon installation and visiting method.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e  # Exit on error\n",
    "source .env.sh  # Load configuration\n",
    "\n",
    "echo \"=== Step 5: Installing KubeVela ===\"\n",
    "\n",
    "# Add KubeVela helm repository\n",
    "echo \"Adding KubeVela helm repository...\"\n",
    "helm repo add kubevela https://charts.kubevela.net/core 2>/dev/null || echo \"Repository already exists\"\n",
    "helm repo update\n",
    "\n",
    "# Check if KubeVela is already installed\n",
    "if helm list -n vela-system | grep -q kubevela; then\n",
    "    echo \"⚠ KubeVela is already installed. Upgrading...\"\n",
    "    HELM_CMD=\"upgrade\"\n",
    "else\n",
    "    echo \"Installing KubeVela...\"\n",
    "    HELM_CMD=\"install\"\n",
    "fi\n",
    "\n",
    "# Install or upgrade KubeVela\n",
    "if helm $HELM_CMD kubevela kubevela/vela-core \\\n",
    "    --create-namespace \\\n",
    "    -n vela-system \\\n",
    "    --wait \\\n",
    "    --timeout 10m; then\n",
    "    echo \"✓ KubeVela helm chart $HELM_CMD completed\"\n",
    "else\n",
    "    echo \"✗ Failed to $HELM_CMD KubeVela\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Wait for KubeVela pods to be ready\n",
    "echo \"Waiting for KubeVela pods to be ready...\"\n",
    "if kubectl wait --namespace vela-system \\\n",
    "    --for=condition=ready pod \\\n",
    "    --selector=app.kubernetes.io/name=vela-core \\\n",
    "    --timeout=600s; then\n",
    "    echo \"✓ KubeVela controller is ready\"\n",
    "else\n",
    "    echo \"✗ KubeVela controller failed to become ready\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"KubeVela installation complete!\"\n",
    "kubectl get pods -n vela-system\n",
    "\n",
    "echo \"\"\n",
    "echo \"Checking KubeVela version...\"\n",
    "kubectl get deployment -n vela-system kubevela-vela-core -o jsonpath='{.spec.template.spec.containers[0].image}'\n",
    "echo \"\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing velaux...\"\n",
    "vela addon enable velaux\n",
    "echo \"\"\n",
    "\n",
    "# port forward velaux\n",
    "nohup vela port-forward -n vela-system addon-velaux 8000:8000 > /dev/null 2>&1 &\n",
    "# open http://localhost:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Complete!\n",
    "\n",
    "Your KubeCon demo environment is now ready. The following components have been installed:\n",
    "\n",
    "- **k3d cluster**: A lightweight Kubernetes cluster for local development\n",
    "- **Crossplane**: Infrastructure orchestration and composition framework\n",
    "- **KubeVela**: Application delivery and management platform\n",
    "- **Custom configurations**: Any providers and compositions from the setup directory\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Explore other notebooks in this directory for demo scenarios\n",
    "2. Check cluster status: `kubectl get pods -A`\n",
    "3. View Crossplane resources: `kubectl get crossplane`\n",
    "4. View KubeVela applications: `kubectl get applications -A`\n",
    "5. When finished, run the cleanup notebook: `00-Env-cleanup.ipynb`\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "If you encountered errors:\n",
    "- Ensure all prerequisites are installed (k3d, kubectl, helm)\n",
    "- Check that ports 6443 and 8090 are available\n",
    "- Review pod logs:\n",
    "  - Crossplane: `kubectl logs -n crossplane-system <pod-name>`\n",
    "  - KubeVela: `kubectl logs -n vela-system <pod-name>`\n",
    "- Try re-running failed cells after investigating the issue\n",
    "\n",
    "For cleanup and teardown, use the `00-Env-cleanup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
